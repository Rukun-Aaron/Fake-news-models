{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIAR dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "train_path = 'LIAR/train.tsv'\n",
    "train_data = pd.read_csv(train_path,sep='\\t', header=None, names=[\"id\", \"label\", \"statement\", \"subject(s)\", \"speaker\",\"speaker's job title\", \"state info\", \"party affiliation\", \"barely true counts\", \"false counts\",\"half true counts\", \"mostly true counts\", \"pants on fire counts\", \"context\"])\n",
    "\n",
    "train_data['label'] = train_data['label'].replace(['pants-fire', 'barely-true','false'], 0)\n",
    "train_data['label'] = train_data['label'].replace(['half-true', 'mostly-true','true'], 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "def analyze_sentiment(text):\n",
    "    if isinstance(text, str) == False and text != 'NaN':\n",
    "        return None\n",
    "    words = word_tokenize(text)\n",
    "   \n",
    "    # filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_text = ' '.join(words)\n",
    "\n",
    "    sentiment_scores = sid.polarity_scores(filtered_text) \n",
    "    return sentiment_scores['compound'] +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2500</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3612</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3182</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.7579</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                          statement\n",
       "0     1.2500  Says the Annies List political group supports ...\n",
       "1     1.3612  When did the decline of coal start? It started...\n",
       "2     1.3182  Hillary Clinton agrees with John McCain \"by vo...\n",
       "3     1.7579  Health care reform legislation is likely to ma...\n",
       "4     1.0000  The economic turnaround started at the end of ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "train_data['sentiment'] = train_data['statement'].apply(analyze_sentiment)\n",
    "\n",
    "\n",
    "train_features = train_data[['sentiment', 'statement']]\n",
    "\n",
    "\n",
    "y_train = train_data['label']\n",
    "\n",
    "\n",
    "train_features.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_statement = vectorizer.fit_transform(train_features['statement'])\n",
    "X_train_sentiment = sparse.csr_matrix(train_features['sentiment'].values.reshape(-1, 1))\n",
    "X_train_features = sparse.hstack((X_train_statement, X_train_sentiment))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_combined_model = MultinomialNB()\n",
    "nb_combined_model.fit(X_train_features, y_train)\n",
    "\n",
    "nb_statement_model = MultinomialNB()\n",
    "nb_statement_model.fit(X_train_statement, y_train)\n",
    "\n",
    "nb_sentiment_model = MultinomialNB()\n",
    "nb_sentiment_model.fit(X_train_sentiment, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_path = 'LIAR/valid.tsv'\n",
    "valid_data = pd.read_csv(valid_path,sep='\\t', header=None, names=[\"id\", \"label\", \"statement\", \"subject(s)\", \"speaker\",\"speaker's job title\", \"state info\", \"party affiliation\", \"barely true counts\", \"false counts\",\"half true counts\", \"mostly true counts\", \"pants on fire counts\", \"context\"])\n",
    "\n",
    "valid_data['label'] = valid_data['label'].replace(['pants-fire', 'barely-true','false'], 0)\n",
    "valid_data['label'] = valid_data['label'].replace(['half-true', 'mostly-true','true'], 1)\n",
    "\n",
    "valid_data['sentiment'] = valid_data['statement'].apply(analyze_sentiment)\n",
    "valid_features = valid_data[['sentiment', 'statement']]\n",
    "y_valid = valid_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_statement = vectorizer.transform(valid_data['statement'])\n",
    "X_valid_sentiment = sparse.csr_matrix(valid_data['sentiment'].values.reshape(-1, 1))\n",
    "X_valid_features = sparse.hstack((X_valid_statement, X_valid_sentiment))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for combined features: 0.5973520249221184\n",
      "Accuracy for statement features: 0.6012461059190031\n",
      "Accuracy for sentiment features: 0.5202492211838006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_combined_pred = nb_combined_model.predict(X_valid_features)\n",
    "combined_accuracy = accuracy_score(valid_data['label'], y_combined_pred)\n",
    "print(\"Accuracy for combined features:\", combined_accuracy)\n",
    "\n",
    "y_statement_pred = nb_statement_model.predict(X_valid_statement)\n",
    "statement_accuracy = accuracy_score(valid_data['label'], y_statement_pred)\n",
    "print(\"Accuracy for statement features:\", statement_accuracy)\n",
    "\n",
    "y_sentiment_pred = nb_sentiment_model.predict(X_valid_sentiment)\n",
    "sentiment_accuracy = accuracy_score(valid_data['label'], y_sentiment_pred)\n",
    "print(\"Accuracy for sentiment features:\", sentiment_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'LIAR/test.tsv'\n",
    "\n",
    "test_data = pd.read_csv(test_path,sep='\\t', header=None, names=[\"id\", \"label\", \"statement\", \"subject(s)\", \"speaker\",\"speaker's job title\", \"state info\", \"party affiliation\", \"barely true counts\", \"false counts\",\"half true counts\", \"mostly true counts\", \"pants on fire counts\", \"context\"])\n",
    "\n",
    "test_data['label'] = test_data['label'].replace(['pants-fire', 'barely-true','false'], 0)\n",
    "test_data['label'] = test_data['label'].replace(['half-true', 'mostly-true','true'], 1)\n",
    "test_data['sentiment'] = test_data['statement'].apply(analyze_sentiment)\n",
    "test_features = test_data[['sentiment', 'statement']]\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_statement = vectorizer.transform(test_data['statement'])\n",
    "X_test_sentiment = sparse.csr_matrix(test_data['sentiment'].values.reshape(-1, 1))\n",
    "X_test_features = sparse.hstack((X_test_statement, X_test_sentiment))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for combined features: 0.6006314127861089\n",
      "Accuracy for statement features: 0.6045777426992897\n",
      "Accuracy for sentiment features: 0.56353591160221\n"
     ]
    }
   ],
   "source": [
    "y_combined_pred_test = nb_combined_model.predict(X_test_features)\n",
    "combined_accuracy_test = accuracy_score(test_data['label'], y_combined_pred_test)\n",
    "print(\"Accuracy for combined features:\", combined_accuracy_test)\n",
    "\n",
    "y_statement_pred_test = nb_statement_model.predict(X_test_statement)\n",
    "statement_accuracy_test = accuracy_score(test_data['label'], y_statement_pred_test)\n",
    "print(\"Accuracy for statement features:\", statement_accuracy_test)\n",
    "\n",
    "y_sentiment_pred_test = nb_sentiment_model.predict(X_test_sentiment)\n",
    "sentiment_accuracy_test = accuracy_score(test_data['label'], y_sentiment_pred_test)\n",
    "print(\"Accuracy for sentiment features:\", sentiment_accuracy_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake reddit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeddit_train_path1 = 'Fakeddit/train1.tsv'\n",
    "fakeddit_train_path2 = 'Fakeddit/train2.tsv'\n",
    "fakeddit_train_path3 = 'Fakeddit/train3.tsv'\n",
    "\n",
    "fakeddit_train_data1 = pd.read_csv(fakeddit_train_path1, sep='\\t')\n",
    "fakeddit_train_data2 = pd.read_csv(fakeddit_train_path2, sep='\\t')\n",
    "fakeddit_train_data3 = pd.read_csv(fakeddit_train_path3, sep='\\t')\n",
    "fakeddit_train_data = pd.concat([fakeddit_train_data1, fakeddit_train_data2, fakeddit_train_data3], ignore_index=True)\n",
    "fakeddit_train_data = fakeddit_train_data[fakeddit_train_data['clean_title'].notna()]\n",
    "fakeddit_train_data['sentiment'] = fakeddit_train_data['clean_title'].apply(analyze_sentiment) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_fakeddit = TfidfVectorizer()\n",
    "X_train_statement_fakeddit = vectorizer_fakeddit.fit_transform(fakeddit_train_data['clean_title'])\n",
    "X_train_sentiment_fakeddit = sparse.csr_matrix(fakeddit_train_data['sentiment'].values.reshape(-1, 1))\n",
    "X_train_features_fakeddit = sparse.hstack((X_train_statement_fakeddit, X_train_sentiment_fakeddit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_combined_model_fakeddit =  MultinomialNB()\n",
    "nb_combined_model_fakeddit.fit(X_train_features_fakeddit, fakeddit_train_data['2_way_label'])\n",
    "\n",
    "nb_title_model_fakeddit = MultinomialNB()\n",
    "nb_title_model_fakeddit.fit(X_train_statement_fakeddit, fakeddit_train_data['2_way_label'])\n",
    "\n",
    "nb_sentiment_model_fakeddit = MultinomialNB()\n",
    "nb_sentiment_model_fakeddit.fit(X_train_sentiment_fakeddit, fakeddit_train_data['2_way_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeddit_valid_path = 'Fakeddit/all_validate.tsv'\n",
    "fakeddit_valid_data = pd.read_csv(fakeddit_valid_path, sep='\\t')\n",
    "fakeddit_valid_data = fakeddit_valid_data[fakeddit_valid_data['clean_title'].notna()]\n",
    "fakeddit_valid_data['sentiment'] = fakeddit_valid_data['clean_title'].apply(analyze_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_statement_fakeddit = vectorizer_fakeddit.transform(fakeddit_valid_data['clean_title'])\n",
    "X_valid_sentiment_fakeddit = sparse.csr_matrix(fakeddit_valid_data['sentiment'].values.reshape(-1, 1))\n",
    "X_valid_features_fakeddit = sparse.hstack((X_valid_statement_fakeddit, X_valid_sentiment_fakeddit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for combined features: 0.7891430869688654\n",
      "Accuracy for statement features: 0.7856771079776663\n",
      "Accuracy for sentiment features: 0.5017389041355163\n"
     ]
    }
   ],
   "source": [
    "y_combined_pred_fakeddit = nb_combined_model_fakeddit.predict(X_valid_features_fakeddit)\n",
    "combined_accuracy_fakeddit = accuracy_score(fakeddit_valid_data['2_way_label'], y_combined_pred_fakeddit)\n",
    "print(\"Accuracy for combined features:\", combined_accuracy_fakeddit)\n",
    "\n",
    "y_statement_pred_fakeddit = nb_title_model_fakeddit.predict(X_valid_statement_fakeddit)\n",
    "statement_accuracy_fakeddit = accuracy_score(fakeddit_valid_data['2_way_label'], y_statement_pred_fakeddit)\n",
    "print(\"Accuracy for statement features:\", statement_accuracy_fakeddit)\n",
    "\n",
    "y_sentiment_pred_fakeddit = nb_sentiment_model_fakeddit.predict(X_valid_sentiment_fakeddit)\n",
    "sentiment_accuracy_fakeddit = accuracy_score(fakeddit_valid_data['2_way_label'], y_sentiment_pred_fakeddit)\n",
    "print(\"Accuracy for sentiment features:\", sentiment_accuracy_fakeddit)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
